{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60c80bdf-71bf-4f3d-9a84-9d706445b978",
   "metadata": {},
   "source": [
    "## Install the necessary SDK packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94100928-9db7-4946-8ed7-fcd23261e162",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade gradio\n",
    "!pip install --upgrade google-cloud-aiplatform\n",
    "!pip install --upgrade google-cloud-storage\n",
    "!pip install --upgrade google-cloud-documentai\n",
    "!pip install --upgrade google-auth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2182a-858b-46fe-b526-c97d22cfcded",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import all the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c4ad21-be49-4198-bbfd-0bb7c609aa9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas\n",
    "\n",
    "import gcp_functions.storage as StorageHelper\n",
    "from gcp_functions.docai import process_document\n",
    "from gcp_functions.config import SummaryParserConfig, ContractParserConfig, get_project_id\n",
    "from gcp_functions.gemini import gemini_response\n",
    "from typing import Callable\n",
    "\n",
    "from google.oauth2.service_account import Credentials\n",
    "import json\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c122447-e36a-47e5-ac96-eb1f9665ff55",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Summarizer Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2245da24-1652-4674-856c-f91222308fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''####################################################################\n",
    "Handler function for uploading a file for doc summarization\n",
    "\n",
    "Will take a local file and upload to a Cloud Storage bucket and then\n",
    "use DocAI processor to make a batch request (to handle larger files)\n",
    "and then parse out the Summary and OCR Text from the json results\n",
    "\n",
    "NOTE: While the processing function can use any DocAI parser, the \n",
    "code assumes the json result to be from the Summarizer parser\n",
    "####################################################################'''\n",
    "def handle_summary_upload(file_url: str):\n",
    "    upload_bucket = SummaryParserConfig.upload_bucket()\n",
    "    \n",
    "    # upload the file from the local dir to the cloud bucket\n",
    "    f, gcs = StorageHelper.file_upload(file_url, upload_bucket)\n",
    "    \n",
    "    project_id = get_project_id()\n",
    "    location = SummaryParserConfig.location()\n",
    "    processor_id = SummaryParserConfig.processor_id()\n",
    "    mime_type = SummaryParserConfig.mime_type()\n",
    "    field_mask = SummaryParserConfig.field_mask()\n",
    "    gcs_input_uri = gcs\n",
    "    gcs_output_uri = f\"gs://{SummaryParserConfig.output_bucket()}\"\n",
    "\n",
    "    # make a request for processing the uploaded file\n",
    "    metadata = process_document(\n",
    "        project_id=project_id, \n",
    "        location=location, \n",
    "        processor_id=processor_id, \n",
    "        mime_type=mime_type, \n",
    "        field_mask=field_mask, \n",
    "        gcs_input_uri=gcs_input_uri, \n",
    "        gcs_output_uri=gcs_output_uri\n",
    "    )\n",
    "\n",
    "    # assumes result json is from a DocAI Workbench Summarizer parser\n",
    "    output_gcs_destination = metadata.individual_process_statuses[0].output_gcs_destination\n",
    "    json_uri, summary, text = StorageHelper.extract_from_summary_output(output_gcs_destination)\n",
    "    \n",
    "    # returns the result location, the summary portion, and the OCR text\n",
    "    return f, summary, text\n",
    "    \n",
    "'''####################################################################\n",
    "Document Summarizer UI component\n",
    "\n",
    "####################################################################'''\n",
    "def summary_component(full_text: gr.components.textbox.Textbox, \n",
    "                      handle_func: Callable):\n",
    "    with gr.Tab(\"Summarize\") as tab:\n",
    "        with gr.Row():\n",
    "            file = gr.Textbox(lines=1, label=\"Upload File\")\n",
    "\n",
    "        with gr.Row():\n",
    "            upload_btn = gr.UploadButton(\n",
    "                \"Click to upload\",\n",
    "                file_types=[\".pdf\"],\n",
    "                file_count=\"single\")\n",
    "                \n",
    "        with gr.Row():\n",
    "            summary = gr.Textbox(lines=20, label=\"Summary\")\n",
    "            \n",
    "        upload_btn.upload(\n",
    "            handle_func,\n",
    "            [upload_btn],\n",
    "            [file, summary, full_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc430553-4b5c-4bfe-9e05-0fc36853d6e8",
   "metadata": {},
   "source": [
    "## Contract Parser Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0d1de-6407-4379-ba54-8a49a3157d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''####################################################################\n",
    "Handler function for uploading a file for doc contract parser\n",
    "\n",
    "Will take a local file and upload to a Cloud Storage bucket and then\n",
    "use DocAI processor to make a batch request (to handle larger files)\n",
    "and then parse out the Entities and OCR Text from the json results\n",
    "\n",
    "NOTE: While the processing function can use any DocAI parser, the \n",
    "code assumes the json result to be from the Contract parser\n",
    "\n",
    "NOTE: The contract parser is hosted in another project, so there is\n",
    "service account usage here\n",
    "####################################################################'''\n",
    "def handle_contract_upload(file_url: str):\n",
    "    upload_bucket = 'gnw-contracts'\n",
    "    \n",
    "    # upload the file from the local dir to the cloud bucket\n",
    "    f, gcs = StorageHelper.file_upload(file_url, upload_bucket, credentials)\n",
    "    \n",
    "    project_id = get_project_id()\n",
    "    location = ContractParserConfig.location()\n",
    "    processor_id = ContractParserConfig.processor_id()\n",
    "    mime_type = ContractParserConfig.mime_type()\n",
    "    field_mask = ContractParserConfig.field_mask()\n",
    "    gcs_input_uri = gcs\n",
    "    gcs_output_uri = f\"gs://{ContractParserConfig.output_bucket()}\"    \n",
    "\n",
    "    # make a request for processing the uploaded file\n",
    "    metadata = process_document(\n",
    "        project_id=project_id, \n",
    "        location=location, \n",
    "        processor_id=processor_id, \n",
    "        mime_type=mime_type, \n",
    "        field_mask=field_mask, \n",
    "        gcs_input_uri=gcs_input_uri, \n",
    "        gcs_output_uri=gcs_output_uri,\n",
    "        credentials=credentials\n",
    "    )\n",
    "    \n",
    "    # assumes result json is from a DocAI Workbench Contract parser\n",
    "    output_gcs_destination = metadata.individual_process_statuses[0].output_gcs_destination\n",
    "    json_uri, entities, text = StorageHelper.extract_from_contract_output(output_gcs_destination)\n",
    "    \n",
    "    df_entities = pandas.DataFrame(entities)\n",
    "    \n",
    "    # returns the result location, the extracted entities, and the OCR text\n",
    "    return f, df_entities, text\n",
    "\n",
    "'''####################################################################\n",
    "Document Contract Parser UI component\n",
    "\n",
    "####################################################################'''\n",
    "def contract_component(full_text: gr.components.textbox.Textbox, \n",
    "                      handle_func: Callable):\n",
    "    with gr.Tab(\"Contracts\") as tab:\n",
    "        with gr.Row():\n",
    "            file = gr.Textbox(lines=1, label=\"Upload Contract\")\n",
    "\n",
    "        with gr.Row():\n",
    "            upload_btn = gr.UploadButton(\n",
    "                \"Click to upload\",\n",
    "                file_types=[\".pdf\"],\n",
    "                file_count=\"single\")\n",
    "                \n",
    "        with gr.Row():\n",
    "            entities = gr.DataFrame(headers=['type', 'mentionText'], \n",
    "                                    column_widths=['200px'],\n",
    "                                    label=\"Entities\", \n",
    "                                    wrap=True)\n",
    "            \n",
    "        upload_btn.upload(\n",
    "            handle_func,\n",
    "            [upload_btn],\n",
    "            [file, entities, full_text])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7243f223-dbb1-47af-8372-4698afb11119",
   "metadata": {
    "tags": []
   },
   "source": [
    "## QA Chat Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65155fa8-6246-4cb5-97e9-340c0cc1a023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''####################################################################\n",
    "QA Chat UI component\n",
    "\n",
    "NOTE: the 'full_text' component should be HIDDEN in the main UI and \n",
    "is used as a way to cache and keep the document available for prompt\n",
    "context\n",
    "####################################################################'''   \n",
    "def qa_component(full_text_component: gr.components.textbox.Textbox):\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot()\n",
    "        \n",
    "    with gr.Row():\n",
    "        msg = gr.Textbox()\n",
    "\n",
    "    def respond(message, history, full_text_component):\n",
    "        resp = gemini_response(message, history, full_text_component)\n",
    "        history.append((message, resp))\n",
    "        return \"\", history\n",
    "\n",
    "    msg.submit(respond, [msg, chatbot, full_text_component], [msg, chatbot])    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50410ea3-8a4d-42c3-806c-1bb991752230",
   "metadata": {},
   "source": [
    "## Main UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4aca8a-44d8-48a6-8c73-27289c3283d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''####################################################################\n",
    "Main UI\n",
    "####################################################################'''   \n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        # using this as a way to cache the full text from the document to use\n",
    "        # for context in the prompt for the QA chatbot\n",
    "        full_text = gr.Textbox(lines=20, label=\"Full Text\", visible=False)\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            # the summary UI\n",
    "            summary_component(full_text, handle_summary_upload)\n",
    "            \n",
    "            # the contract UI\n",
    "            contract_component(full_text, handle_contract_upload)\n",
    "        with gr.Column():\n",
    "            # the QA chatbot\n",
    "            qa_component(full_text)\n",
    "        \n",
    "\n",
    "demo.launch(share=True, debug=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c4659-89be-4add-90e0-f6a23dd9a1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
